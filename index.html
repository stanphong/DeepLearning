<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="description" content="This is an awesome website">
  <title>Phong2's Website</title>
  <link rel="stylesheet" href="./style2.css"
</head>
<body>
    <section class="modau">
      <header>
        <a href="https://hcmut.edu.vn/" target="_blank"  class="logo">Ho Chi Minh University<span>.</span></a>
        <ul class="navigation">
          <li><a href="#banner">Home</a></li>
          <li><a href="#definition">Definition</a></li>
          <li><a href="#history">History</a></li>
          <li><a href="#architectures">Architectures</a></li>
          <li><a href="#achievements">Achievements</a></li>
          <li><a href="#about">About Us</a></li>
        </ul>
      </header>
      <section class="banner" id="banner">
          <div class="content">
            <h2>Deep Learning</h2>
            <p>Team: "Ông trùm bất động sản"</p>
            <p>class: CC02</p>
            <a href="#" class="btn">Group report</a>
          </div>
      </section>
    </section>
    <section class="definition" id="definition">
      <h2 class="titleText">Definition</h2>
      <p class="quote"><span>"</span><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep learning</a> (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised, is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.<span>"</span></p>
    </section>
    <section class="history" id="history">
      <h2 class="titleText" style="color: #00FFFF;">History and Development</h2>
      <h1 class="tieude">Timeline of Deep Learning</h1>
      <div class="container">
        <div class="timeline">
          <ul>
            <li>
              <div class="timeline-content">
                <h2 class="date">1943</h2>
                <h1>McCulloch Pitts Neuron – Beginning</h1>
                <p>The history of deep learning dates back to this year when Warren McCulloch and Walter Pitts created a computer model based on the neural networks of the human brain. Warren McCulloch and Walter Pitts used a combination of mathematics and algorithms they called threshold logic to mimic the thought process. Since then, deep learning has evolved steadily, over the years with two significant breaks in its development.</p>
              </div>
              <div class="hide"><img src="image1.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1960</h2>
                <h1>The First Backpropagation Model</h1>
                <p>The development of the basics of a continuous Back Propagation Model is credited to Henry J. Kelley.</p>
              </div>
              <div class="hide"><img src="image2.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1962</h2>
                <h1>Backpropagation With Chain Rule</h1>
                <p>Stuart Dreyfus came up with a simpler version based only on the chain rule in. The concept of back propagation existed in the early 1960s but only became useful until 1985.</p>
              </div>
              <div class="hide"><img src="image3.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1965</h2>
                <h1>Birth Of Multilayer Neural Network</h1>
                <p>The earliest efforts in developing deep learning algorithms date to this year, when Alexey Grigoryevich Ivakhnenko and Valentin Grigorʹevich Lapa used models with polynomial (complicated equations) activation functions, which were subsequently analysed statistically.</p>
              </div>
              <div class="hide"><img src="image4.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1970</h2>
                <h1>Backpropagation Is Computer Coded</h1>
                <p>Back propagation, the use of errors in training Deep Learning models, evolved significantly. This was when Seppo Linnainmaa wrote his master’s thesis, including a FORTRAN code for back propagation. Unfortunately, the concept was not applied to neural networks until 1985</p>
              </div>
              <div class="hide"><img src="image6.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1979</h2>
                <h1>Neocognitron – First CNN Architecture</h1>
                <p>Convolutional neural networks were first used by Kunihiko Fukushima who designed the neural networks with multiple pooling and convolutional layers.</p>
                <p>Kunihiko Fukushima developed an artificial neural network, called Neocognitron , which used a multi-layered and hierarchical design. The multi-layered and hierarchical design allowed the computer to learn to recognize visual patterns. The networks resembled modern versions and were trained with a reinforcement strategy of recurring activation in multiple layers, gaining strength over time.</p>
              </div>
              <div class="hide"><img src="image5.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1985</h2>
                <h1>Boltzmann Machine</h1>
                <p>David H. Ackley, Geoffrey Hinton and Terrence Sejnowski create Boltzmann Machine that is a stochastic recurrent neural network. This neural network has only input layer and hidden layer but no output layer.</p>
              </div>
              <div class="hide"><img src="image7.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1985</h2>
                <h1>Implementation Of Backpropagation</h1>
                <p>This was when Rumelhart, Williams, and Hinton demonstrated back propagation in a neural network could provide “interesting” distribution representations. Philosophically, this discovery brought to light the question within cognitive psychology of whether human understanding relies on symbolic logic (computationalism) or distributed representations (connectionism).</p>
              </div>
              <div class="hide"><img src="image8.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1986</h2>
                <h1>Restricted Boltzmann Machine</h1>
                <p>Paul Smolensky comes up with a variation of Boltzmann Machine where there is not intra layer connection in input and hidden layer. It is known as Restricted Boltzmann Machine (RBM). It would become popular in years to come especially for building recommender systems.</p>
              </div>
              <div class="hide"><img src="image9.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1989</h2>
                <h1>CNN Using Backpropagation</h1>
                <p>Yann LeCun  applied the standard backpropagation algorithm, which had been around as the reverse mode of automatic differentiation since 1970, to a deep neural network with the purpose of recognizing handwritten ZIP codes on mail. While the algorithm worked, training required 3 day.</p>
              </div>
              <div class="hide"><iframe width=90% height=90% src="https://www.youtube.com/embed/FwFduRA_L6Q" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1991</h2>
                <h1>Vanishing Gradient Problem Appears</h1>
                <p>Sepp Hochreiter identifies the problem of vanishing gradient which can make the learning of deep neural network extremely slow and almost impractical. This problem will continue to annoy deep learning community for many more years to come.</p>
              </div>
              <div class="hide"><img src="image10.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">1997</h2>
                <h1>LSTM</h1>
                <p>Sepp Hochreiter and Jürgen Schmidhuber publishes a milestone paper on “Long Short-Term Memory” (LSTM). It is a type of recurrent neural network architecture which will go on to revolutionize deep learning in decades to come.</p>
              </div>
              <div class="hide"><img src="image11.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">2006</h2>
                <h1>Deep Belief Network</h1>
                <p>Publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh showed how a many-layered feedforward neural network could be effectively pre-trained one layer at a time, treating each layer in turn as an unsupervised restricted Boltzmann machine, then fine-tuning it using supervised backpropagation.</p>
              </div>
              <div class="hide"><img src="image12.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">2009</h2>
                <h1>ImageNet Is Launched</h1>
                <p>Finding enough labeled data has always been a challenge for Deep Learning community. In 2009 Fei-Fei Li, a professor at Stanford, launches ImageNet which is a database of 14 million labeled images. It would serve as a benchmark for the deep learning researchers who would participate in ImageNet competitions (ILSVRC) every year.</p>
              </div>
              <div class="hide"><img src="image13.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">2012</h2>
                <h1>AlexNet Starts Deep Learning Boom</h1>
                <p>AlexNet, a GPU implemented CNN model designed by Alex Krizhevsky, wins Imagenet’s image classification contest with accuracy of 84%.  It is a huge jump over 75% accuracy that earlier models had achieved. This win triggers a new deep learning boom globally.</p>
              </div>
              <div class="hide"><img src="image14.jpg" alt="alt"></div>
            </li>
            <li>
              <div class="timeline-content">
                <h2 class="date">2014</h2>
                <h1>The Birth Of GANs</h1>
                <p>Generative Adversarial Neural Network also known as GAN is created by Ian Goodfellow. GANs open a whole new doors of application of deep learning in fashion, art, science due it’s ability to synthesize real like data.</p>
              </div>
              <div class="hide"><img src="image15.jpg" alt="alt"></div>
            </li>
      </div>
    </section>
    <section class="architectures" id="architectures">
      <h2 class="titleText">Some prominent architectures</h2>
        <div class="intro">
        <div class="text">
          <p>Deep Learning Architecture is separated to 2 different kind of learning that are: Supervised Learning and Unsupervised Learning.</p>
          <p>In this presentation, we will look at the top 5 widely-used deep learning architectures ,their designs, variations  ,their advantages and disadvantages, and there are:</p>
          <ol>
            <li><a href="#cnn">Convolutional Neural Networks (CNN)</a></li>
            <li><a href="#rnn">Recurrent Neural Networks (RNN)</a></li>
            <li><a href="#auto">Autoencoders</a></li>
            <li><a href="#gan">Generative Adversarial Networks (GAN)</a></li>
            <li><a href="#resnets">ResNets</a></li>
          </ol>
        </div>
        <div class="image">
          <img src="archi1.jpg" alt="Deep learning summary tree">
        </div>
      </div>
      <div class="part">
        <div class="intro1">
          <div class="text1">
            <h3 id="cnn">1. Convolutional Neural Networks (CNN)</h3>
            <p>CNN are the popular choice of neural networks for different Computer Vision tasks such as image recognition,… .</p>
              <p style="margin-bottom:-20px;">There are 4 steps in designing a CNN:</p>
              <ul>
                <li><b>Convolution:</b> The input signal is received at this stage</li>
                <li><b>Subsampling:</b> Inputs received from the convolution layer are smoothened to reduce the sensitivity of the filters to noise or any other variation</li>
                <li><b>Activation:</b> This layer controls how the signal flows from one layer to the other, similar to the neurons in our brain</li>
                <li><b>Fully connected:</b> In this stage, all the layers of the network are connected with every neuron from a preceding layer to the neurons from the subsequent layer.</li>
              </ul>
            </div>
          <div class="image1">
            <img src="archi2.jpg" alt="CNN graph">
            <p><b>A sample CNN in action</b></p>
          </div>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <th>Advantages</th>
              <th>Disadvantages</th>
            </tr>
            <tr>
              <td>
                <ul>
                  <li>Very good for visual recognition</li>
                  <li>Once a segment within a particular sector of an image is learned, the CNN can recognize that segment present anywhere else in the image</li>
                </ul>
              </td>
              <td>
                <ul>
                  <li>CNN is highly dependent on the size and quality of the training data</li>
                  <li>Highly susceptible to noise</li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>
        <p style="padding:20px;"><i>*A Few popular CNN: LeNet-5, AlexNet, VGG-16,Inception….</i></p>
        <div class="intro1">
          <div class="text1">
            <h3 id="rnn">2. Recurrent Neural Networks (RNN)</h3>
            <p>RNN have been very popular in areas where the sequence in which the information is presented is crucial. So, they have a lot of real-world applications such as natural language processing, speech synthesis and machine translation.</p>
              <p style="margin-bottom:-20px;">Over the years, quite a few varieties of RNNS have been researched and developed:</p>
              <ul>
                <li><b>Bidirectional RNN</b> – The output in this type of RNN depends not only on the past but also the future outcomes</li>
                <li><b>Deep RNN</b> – In this type of RNN, there are multiple layers present per step, allowing for a greater rate of learning and more accuracy</li>
              </ul>
            </div>
          <div class="image1">
            <img src="archi3.jpg" alt="CNN graph" style="height: 50%; width:50%;">
          </div>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <th>Advantages</th>
              <th>Disadvantages</th>
            </tr>
            <tr>
              <td>
                <ul>
                  <li>Unlike a traditional neural network, an RNN shares the same parameters across all steps. This greatly reduces the number of parameters that we need to learn</li>
                  <li>RNNs can be used along with CNNs to generate accurate descriptions for unlabeled images</li>
                </ul>
              </td>
              <td>
                <ul>
                  <li>RNNs find it difficult to track long-term dependencies. This is especially true in case of long sentences and paragraphs having too many words in between the noun and the verb.</li>
                  <li>RNNs cannot be stacked into very deep models. This is due to the activation function used in RNN models, making the gradient decay over multiple layers.</li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>
        <div class="intro1">
          <div class="text1">
            <h3 id="auto">3. Autoencoders</h3>
            <p>Autoencoders apply the principle of backpropagation in an unsupervised environment. Autoencoders, interestingly, have a close resemblance to Principal Component Analysis except that they are more flexible. Some applications of Autoencoders is anomaly detection – for instance, detecting fraud in financial transactions in banks. The core task of it is to identify and determine what constitutes regular, normal data and then identify the outliers or anomalies.</p>
              <p style="margin-bottom:-20px;">There are 4 major types of Autoencoders:</p>
              <ul>
                <li><b>Vanilla autoencoder</b> – the simplest form of autoencoders there is, i.e. a neural net with one hidden layer</li>
                <li><b>Multilayer autoencoder</b> – when one hidden layer is not enough, an autoencoder can be extended to include more hidden layers</li>
                <li><b>Convolutional autoencoder</b> – In this type, convolutions are used in the autoencoders instead of fully-connected layers</li>
                <li><b>Regularized autoencoder</b> – this type of autoencoders use a special loss function that enables the model to have properties beyond the basic ability to copy a given input to the output.</li>
              </ul>
            </div>
          <div class="image1">
            <img src="archi4.jpg" alt="CNN graph">
            <p><b>A basic representation of Autoencoder</b></p>
          </div>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <th>Advantages</th>
              <th>Disadvantages</th>
            </tr>
            <tr>
              <td>
                <ul>
                  <li>Autoencoders give a resultant model which is primarily based on the data rather than predefined filters</li>
                  <li>Very less complexity means it’s easier to train them</li>
                </ul>
              </td>
              <td>
                <ul>
                  <li>Training time can be very high sometimes</li>
                  <li>If the training data is not representative of the testing data, then the information that comes out of the model can be obscured and unclear</li>
                  <li>Some autoencoders, especially of the variational type, cause a deterministic bias being introduced in the model</li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>
        <div class="intro1">
          <div class="text1">
            <h3 id="gan">4. Generative Adversarial Networks</h3>
            <p>The basic premise of Generative Adversarial Networks (GANs) is the training of two deep learning models simultaneously. These deep learning networks basically compete with each other – one model that tries to generate new instances or examples is called as the generator. The other model that tries to classify if a particular instance originates from the training data or from the generator is called as the discriminator.</p>
            <p>GANs was a concept by Ian Goodfellow in 2014, and have large applications in Computer Vision, especially image generation.</p>
            </div>
          <div class="image1">
            <img src="archi5.jpg" alt="CNN graph">
            <p><b>General architecture of GAN</b></p>
          </div>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <th>Advantages</th>
              <th>Disadvantages</th>
            </tr>
            <tr>
              <td>
                <ul>
                  <li>Per Goodfellow, GANs allow for efficient training of classifiers in a semi-supervised manner</li>
                  <li>Because of the improved accuracy of the model, the generated data is almost indistinguishable from the original data</li>
                </ul>
              </td>
              <td>
                <ul>
                  <li>Generator and discriminator working efficiently is crucial to the success of GAN. The whole system fails even if one of them fails</li>
                  <li>Both the generator and discriminator are separate systems and trained with different loss functions. Hence the time required to train the entire system can get quite high.</li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>
        <div class="intro1">
          <div class="text1">
            <h3 id="resnets">5. ResNets</h3>
            <p>As you know, CNNs are highly useful when it comes to solving image classification and visual recognition problems. But when the tasks become more complex, training of the neural network starts to get a lot more difficult, as additional deep layers are required to compute and enhance the accuracy of the model. Residual learning is a concept designed to tackle this  problem, and the resultant architecture is known as a ResNet.</p>
            <p>A ResNet consists of a number of residual modules – where each module represents a layer. Each layer consists of a set of functions to be performed on the input. The depth of a ResNet can vary greatly – the one developed by Microsoft researchers for an image classification problem had 152 layers</p>
            </div>
          <div class="image1">
            <img src="archi6.jpg" alt="CNN graph">
            <p><b>A basic building block of ResNet</b></p>
          </div>
        </div>
        <table class="table">
          <tbody>
            <tr>
              <th>Advantages</th>
              <th>Disadvantages</th>
            </tr>
            <tr>
              <td>
                <ul>
                  <li>ResNets are more accurate and require less weights than LSTMs and RNNs in some cases</li>
                  <li>They are highly modular. Hundreds and thousands of residual layers can be added to create a network and then trained.</li>
                  <li>ResNets can be designed to determine how deep a particular network needs to be.</li>
                </ul>
              </td>
              <td>
                <ul>
                  <li>If the layers in a ResNet are too deep, errors can be hard to detect and cannot be propagated back quickly and correctly. At the same time, if the layers are too narrow, the learning might not be very efficient.</li>
                </ul>
              </td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>
    <section class="achievements" id="achievements">
      <div class="nen">
        <h2 style="padding-bottom: 30px;" class="titleText">Some recent outstanding achievements of Deep learning</h2>
        <div class="trong">
          <h3><i>1. Google Neural Machine Translation</i></h3>
          <p>Google Neural Machine Translation (GNMT) is a neural machine translation (NMT) system developed by Google that uses an artificial neural network to increase fluency and accuracy in Google Translate.</p>
          <p>That very idea was realized by Google engineers at the end of 2016. Architecture of NN was build on the seq2seq model.</p>
          <p>The only exception is that between the encoder and decoder there are 8 layers of LSTM-RNN that have residual connections between layers with some tweaks for accuracy and speed.</p>
          <p>The system requires a “token” at the beginning of the input sentence which specifies the language you’re trying to translate the phrase into.</p>
          <p>This improves translation quality and enables translations even between two languages which the system hasn’t seen yet, a method termed “Zero-Shot Translation.”</p>
          <img src="achieve1.jpg">
          <p>The key outcome: closing down the gap with humans in accuracy of the translation by 55–85% (estimated by people on a 6-point scale). It is difficult to reproduce good results with this model without the huge dataset that Google has</p>
          <span>For more details on: </span>
          <a href="https://ai.googleblog.com/2016/11/zero-shot-translation-with-googles.html" target="_blank">Google AI Blog</a>
          <h3><i>2. Lip reading</i></h3>
          <p>Lip reading is the ability of recognizing what is being said only from visual information</p>
          <p>Google Deepmind, in collaboration with Oxford University, reported in the article, “Lip Reading Sentences in the Wild” on how their model, which had been trained on a television dataset, was able to surpass the professional lip reader from the BBC channel.</p>
          <p>There are 100,000 sentences with audio and video in the dataset. Model: LSTM on audio, and CNN + LSTM on video. These two state vectors are fed to the final LSTM, which generates the result (characters).</p>
          <img src="achieve2.jpg">
          <p>Different types of input data were used during training: audio, video, and audio + video. In other words, it is an “omnichannel” model.</p>
          <img src="achieve3.gif">
          <h3><i>3. Synthesizing Obama: synchronization of the lip movement from audio</i></h3>
          <p>The University of Washington has successfully done a specific task of learning to generate video of Obama from his voice and stock footage. The choice fell on him due to the huge number of his performance recordings online (17 hours of HD video).</p>
          <a href="https://www.youtube.com/watch?v=9Yq67CjDqvw&t=25s" target=_blank><img src="achieve4.jpg"></a>
          <p style="padding: 20px;">Here is the model of this idea</p>
          <img src="achieve5.jpg">
          <h3><i>4. OCR: Google Maps and Street View</i></h3>
          <p>Text recognition in a natural environment is a challenging computer vision and machine learning problem</p>
          <img src="achieve6.jpg">
          <p>In 2017, Google Brain Team has introduced a new OCR (Optical Character Recognition) engine into its Maps, through which street signs and store signs are recognized.</p>
          <p>Their algorithm achieves 84.2% accuracy on the challenging French Street Name Signs (FSNS) dataset, significantly outperforming the previous state-of-the-art systems</p>
          <p>To recognize each sign, the network uses up to four of its photos. The features are extracted with the CNN, scaled with the help of the spatial attention (pixel coordinates are taken into account), and the result is fed to the LSTM.</p>
          <img src="achieve7.jpg">
          <h3><i>5. GANs</i></h3>
          <p>One of the hottest topics in Deep Learning is Generative Adversarial Networks (GANs)</p>
          <p>Generative adversarial networks (GANs) are a class of neural networks that are used in unsupervised machine learning. Most often, this idea is used to work with images.</p>
          <p>The idea is in the competition of two networks — the generator and the discriminator. The first network creates a picture, and the second one tries to understand whether the picture is real or generated.</p>
          <img src="achieve8.jpg" style="height:70%; width:70%;">
          <p>They help to solve some tasks like:</p>
          <h4>Image retrieval for historical archives</h4>
          <img src="achieve9.jpg">
          <h4>Text translation into images</h4>
          <img src="achieve10.jpg">
          <img src="achieve11.jpg" style="height:50%;width:50%;">
          <h4>Drug discovery</h4>
          <img src="achieve12.jpg" style="height:40%;width:40%;">
          <h3><i>6. Pix2pix</i></h3>
          <p>One of the eye-catching articles of 2016 is, “Image-to-Image Translation with Conditional Adversarial Networks” by Berkeley AI Research (BAIR). Researchers solved the problem of image-to-image generation, when, for example, it was required to create a map using a satellite image, or realistic texture of the objects using their sketch.</p>
          <img src="achieve13.jpg">
          <h3><i>7. CycleGAN</i></h3>
          <p>In order to apply Pix2Pix, you need a dataset with the corresponding pairs of pictures from different domains. However, if you want to do something more complicated like “transfiguring” objects or styling, then pairs of objects cannot be found in principle.</p>
          <p>Therefore, authors of Pix2Pix decided to develop their idea and came up with CycleGAN for transfer between different domains of images without specific pairs — “Unpaired Image-to-Image Translation.”</p>
          <p>The idea is to teach two pairs of generator-discriminators to transfer the image from one domain to another and back, while we require a cycle consistency</p>
          <img src="achieve14.jpg">
          <img src="achieve15.jpg">
          <h3><i>8. Learning robots</i></h3>
          <p>In OpenAI, they have been actively studying an agent’s training by humans in a virtual environment, which is safer for experiments than in real life.</p>
          <p>In one of the studies, the team showed that one-shot learning is possible: a person shows in VR how to perform a certain task, and one demonstration is enough for the algorithm to learn it and then reproduce it in real conditions.</p>
          <a href="https://openai.com/blog/robots-that-learn/" target="_blank"><img src="achieve16.gif"></a>
          <h3><i>9. Movement in complex environments</i></h3>
          <p>There is another study from DeepMind which is about teaching the robot complex behavior (walk, jump, etc.), and even do it similar to the human. This will involve a lot about loss function to encourage the desired behavior. However, it would be preferable that the algorithm learned complex behavior itself by leaning with simple rewards.</p>
          <p>Researchers managed to achieve this: they taught agents (body emulators) to perform complex actions by constructing a complex environment with obstacles and with a simple reward for progress in movement.</p>
          <p>The result is impressive (with sound)</p>
          <div style="position:relative;left:18%;">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/itACOKJHYmw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>
          <h3><i>10. Self-driving cars</i></h3>
          <p>The self-driving car sphere is intensively developing, and the cars are actively tested. Some of the pioneers in this field are Tesla, Google Waymo, Volvo, etc... Even though there are many scandals recently related to the safety of it, autonomous car is still a prominent technology in the future. Deep learning has taken over the major subfields of autonomous driving through 4 pillars</p>
          <img src="achieve18.jpg" style="width:80%;height:80%;">
          <span>For further explanation of how Deep Learning affects each of these modules on:</span>
          <a href="https://becominghuman.ai/deep-learning-algorithms-in-self-driving-cars-14b13a895068" target="_blank">Becominghuman</a>
        </div>
      </div>
    </section>
    <section class="about" id="about">
      <div class="wrapper">
        <h2>Our team</h2>
        <div class="team">
          <div class="team_member">
            <img src="member1.jpg" class="team_img">
            <h3 class="user_name">Đỗ Minh Phong</h3>
            <h5>Web designer</h5>
            <p>2052207</p>
          </div>
          <div class="team_member">
            <img src="member2.jpg" class="team_img">
            <h3 class="user_name">Ngô Quang Huy</h3>
            <h5>Latex designer</h5>
            <p>2052106</p>
          </div>
          <div class="team_member">
            <img src="member4.jpg" class="team_img">
            <h3 class="user_name">Nguyễn Huy Hoàng</h3>
            <h5>Slide designer</h5>
            <p>1852382</p>
          </div>
          <div class="team_member">
            <img src="member3.jpg" class="team_img">
            <h3 class="user_name">Nguyễn Ngọc Hoàng Chiến</h3>
            <h5>Video editor</h5>
            <p>2052895</p>
          </div>
        </div>
      </div>
    </section>
    <script type="text/javascript">
      window.addEventListener('scroll', function(){
        const header = document.querySelector('header');
        header.classList.toggle("sticky", window.scrollY > 0);
      });
    </script>
</body>
</html>
